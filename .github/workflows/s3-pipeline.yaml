name: Deploy to S3

on:
  push:
    branches:
      - main

permissions:
  id-token: write
  contents: read

jobs:
  deploy:
    runs-on: ubuntu-latest
    steps:
    - name: Checkout repository
      uses: actions/checkout@v3
      with:
        fetch-depth: 2  # Fetch the last two commits to detect renames

    - name: Configure AWS credentials from OpenID Connect
      uses: aws-actions/configure-aws-credentials@v3
      with:
        role-to-assume: arn:aws:iam::471112860139:role/release-notes-role-gh-actions
        aws-region: us-west-2

    - name: Install necessary packages
      run: |
        sudo apt-get update
        sudo apt-get install -y awscli jq

    - name: Calculate MD5 hashes for local files (only inside addons)
      run: |
        echo "Calculating MD5 hashes for local files..."
        find ./addons -type f -exec md5sum {} + | sed 's| ./addons/| |' > local_md5.txt
        echo "MD5 hashes for local files:"
        cat local_md5.txt

    - name: Get S3 file metadata
      run: |
        echo "Fetching S3 object metadata..."
        aws s3api list-objects-v2 --bucket persistentstack-us-west-2-releasenotesbucketdbdb4f-pys20oqkdpki \
        --prefix "" --query "Contents[].{Key: Key, ETag: ETag}" --output json > s3_files.json

        # Extract S3 keys and ETags (removing quotes from ETag)
        jq -r '.[] | "\(.Key) \(.ETag)"' s3_files.json | tr -d '"' > s3_md5.txt
        echo "S3 file metadata with ETags:"
        cat s3_md5.txt

    - name: Compare MD5 and detect changes
      run: |
        echo "Comparing local and S3 file lists..."
        
        # Prepare lists for added and changed files
        awk '{print $1}' s3_md5.txt | sort > s3_files.txt
        awk '{print $2}' local_md5.txt | sort > local_files.txt

        # Find files to delete (present in S3 but missing locally)
        comm -23 s3_files.txt local_files.txt > to_delete.txt  # Files in S3 but not in local (to delete)
        
        # Find files to add (present locally but missing in S3)
        comm -13 s3_files.txt local_files.txt > to_add.txt     # Files in local but not in S3 (to add)
        
        # Detect changed files by comparing MD5 hashes
        join -1 2 -2 2 -o 1.1,1.2,2.1 <(sort -k 2 local_md5.txt) <(sort -k 2 s3_md5.txt) \
        | awk '$1 != $3' > changed_files.txt  # Changed file hashes

        echo "Files to delete from S3:"
        cat to_delete.txt

        echo "Files to add to S3:"
        cat to_add.txt

        echo "Files that have changed:"
        cat changed_files.txt

    - name: Delete removed files from S3
      if: success()
      run: |
        echo "Deleting files from S3..."
        cat to_delete.txt | xargs -I {} aws s3 rm s3://persistentstack-us-west-2-releasenotesbucketdbdb4f-pys20oqkdpki/{} || true

    - name: Upload new and changed files to S3
      if: success()
      run: |
        echo "Uploading new files to S3..."
        cat to_add.txt | while read file; do
          echo "Uploading $file"
          aws s3 cp ./addons/$file s3://persistentstack-us-west-2-releasenotesbucketdbdb4f-pys20oqkdpki/$file --metadata-directive REPLACE
        done
        
        echo "Uploading changed files to S3..."
        cat changed_files.txt | while read file; do
          echo "Uploading $file"
          aws s3 cp ./addons/$file s3://persistentstack-us-west-2-releasenotesbucketdbdb4f-pys20oqkdpki/$file --metadata-directive REPLACE
        done
